{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0553a8c8-2ce8-4f9b-8e11-7772b77192f0",
   "metadata": {},
   "source": [
    "# Document Reviewer Agent using LangGraph, LangChain and Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ee177-d8f1-4b97-9b0b-f3ef14e7a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langgraph langchain langchain_openai langchain_core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5461b6-a40c-4d76-a039-45ea6bcf4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "import operator\n",
    "from dataclasses import dataclass, field, fields\n",
    "from typing_extensions import Annotated, Literal\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langsmith import traceable\n",
    "from tavily import TavilyClient\n",
    "from typing import Any, Optional\n",
    "from IPython.display import Image, display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d39839-5a6e-465e-9749-08046d4f8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(model=\"deepseek-r1:latest\", temperature=0)#initialize model-specify which one you want to use, pull from ollama before\n",
    "llm_json_mode=ChatOllama(model=\"deepseek-r1:latest\", temperature=0, format=\"json\")#we generate structured outputs since this type of input needed for LangChain..\n",
    "#temperature=0 means you want to generate deterministic outputs-same input same output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073456e-ff57-4692-8a13-5e79d3f53a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we define our state\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class ReviewState:\n",
    "    document_path: str = field(default=None) # The original doc\n",
    "    sections: Annotated[list, operator.add] = field(default_factory=list)\n",
    "    summaries: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    reviews: Annotated[list, operator.add] = field(default_factory=list)\n",
    "    final_report: str = field(default=None) # Final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60078438-2c83-4dfe-b1ab-e8ce9868d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the input file, splits it into paragraphs and returns them to be stored in state.sections\n",
    "def load_document(state: ReviewState):\n",
    "    with open(state.document_path, 'r') as f:\n",
    "        text = f.read()\n",
    "    sections = text.split(\"\\n\\n\")  # paragraph-based splitting\n",
    "    return {\"sections\": sections}\n",
    "    \n",
    "#For each section it prompts the LLM to summarize it and store the results in a list then return that list\n",
    "def summarize_section(state: ReviewState):\n",
    "    summaries = []\n",
    "    for section in state.sections:\n",
    "        prompt = f\"Summarize the following section:\\n\\n{section}\"\n",
    "        result = llm.invoke([SystemMessage(content=prompt)])\n",
    "        summaries.append(result.content.strip())\n",
    "    return {\"summaries\": summaries}\n",
    "\n",
    "#For each section it asks the LLM to critique it on clarity, grammar, and structure, stores that feedback\n",
    "def review_sections(state: ReviewState):\n",
    "    reviews = []\n",
    "    for i, section in enumerate(state.sections):\n",
    "        prompt = (\n",
    "            f\"Review this section of a document:\\n\\n{section}\\n\\n\"\n",
    "            f\"Provide suggestions for clarity, grammar, and structure.\"\n",
    "        )\n",
    "        result = llm.invoke([SystemMessage(content=prompt)])\n",
    "        reviews.append(result.content.strip())\n",
    "    return {\"reviews\": reviews}\n",
    "\n",
    "#For each section, show its summary and the review.\n",
    "def compile_report(state: ReviewState):\n",
    "    report = \"## Document Review Report\\n\\n\"\n",
    "    for i, (summary, review) in enumerate(zip(state.summaries, state.reviews)):\n",
    "        report += f\"### Section {i+1}\\n\"\n",
    "        report += f\"**Summary:**\\n{summary}\\n\\n\"\n",
    "        report += f\"**Review:**\\n{review}\\n\\n\"\n",
    "    return {\"final_report\": report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa1d3e-38b2-48d9-ab95-15e1a3c1a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we build the LangGraph\n",
    "builder = StateGraph(ReviewState, output=ReviewState)\n",
    "builder.set_entry_point(\"load_document\")\n",
    "\n",
    "builder.add_node(\"load_document\", load_document)\n",
    "builder.add_node(\"summarize_section\", summarize_section)\n",
    "builder.add_node(\"review_sections\", review_sections)\n",
    "builder.add_node(\"compile_report\", compile_report)\n",
    "\n",
    "builder.add_edge(\"load_document\", \"summarize_section\")\n",
    "builder.add_edge(\"summarize_section\", \"review_sections\")\n",
    "builder.add_edge(\"review_sections\", \"compile_report\")\n",
    "builder.add_edge(\"compile_report\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877d26c-00fa-46ab-bb7e-362104a0b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-here we run the agent\n",
    "state = ReviewState(document_path=\"research.txt\")  # replace with your doc\n",
    "result = graph.invoke(state)\n",
    "print(result[\"final_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30a375-2f67-43de-9593-8910f42c1c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
